{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/alogomachine/titannic-logistic?scriptVersionId=88904683\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-26T17:23:37.54351Z","iopub.execute_input":"2022-02-26T17:23:37.543769Z","iopub.status.idle":"2022-02-26T17:23:37.553016Z","shell.execute_reply.started":"2022-02-26T17:23:37.54374Z","shell.execute_reply":"2022-02-26T17:23:37.552063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:37.718739Z","iopub.execute_input":"2022-02-26T17:23:37.719513Z","iopub.status.idle":"2022-02-26T17:23:37.727018Z","shell.execute_reply.started":"2022-02-26T17:23:37.719466Z","shell.execute_reply":"2022-02-26T17:23:37.726152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv ('../input/titanic/train.csv')\ntest_df = pd.read_csv('../input/titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:37.910601Z","iopub.execute_input":"2022-02-26T17:23:37.91093Z","iopub.status.idle":"2022-02-26T17:23:37.926688Z","shell.execute_reply.started":"2022-02-26T17:23:37.910896Z","shell.execute_reply":"2022-02-26T17:23:37.925857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:38.046966Z","iopub.execute_input":"2022-02-26T17:23:38.047693Z","iopub.status.idle":"2022-02-26T17:23:38.059975Z","shell.execute_reply.started":"2022-02-26T17:23:38.047639Z","shell.execute_reply":"2022-02-26T17:23:38.05908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.columns","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:38.226239Z","iopub.execute_input":"2022-02-26T17:23:38.226802Z","iopub.status.idle":"2022-02-26T17:23:38.232735Z","shell.execute_reply.started":"2022-02-26T17:23:38.226763Z","shell.execute_reply":"2022-02-26T17:23:38.231881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 查看缺失值及其比例\nper_na = pd.concat([pd.Series(train_df.isna().sum().values),pd.Series((train_df.isna().sum().values / train_df.shape[0])*100)],axis=1)\nper_na.columns = ['Na_Counts','percentOfNa']\nper_na.index = train_df.columns\nper_na","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:38.41207Z","iopub.execute_input":"2022-02-26T17:23:38.412765Z","iopub.status.idle":"2022-02-26T17:23:38.428175Z","shell.execute_reply.started":"2022-02-26T17:23:38.412729Z","shell.execute_reply":"2022-02-26T17:23:38.427551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:38.57551Z","iopub.execute_input":"2022-02-26T17:23:38.576069Z","iopub.status.idle":"2022-02-26T17:23:38.603468Z","shell.execute_reply.started":"2022-02-26T17:23:38.576028Z","shell.execute_reply":"2022-02-26T17:23:38.602834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 填充缺失值，因为Cabin缺失值比例>20,所以直接删除不考虑\n# 而Embarked是类别标签，缺失值较少，所以可以用出现最多的标签去填充\ntrain_data = train_df.copy()#创建副本\ntrain_data = train_data.drop('Cabin',axis=1)\ntrain_data['Embarked'].fillna(max(dict(train_data['Embarked'].value_counts())),inplace=True) ","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:38.688126Z","iopub.execute_input":"2022-02-26T17:23:38.688816Z","iopub.status.idle":"2022-02-26T17:23:38.697114Z","shell.execute_reply.started":"2022-02-26T17:23:38.688775Z","shell.execute_reply":"2022-02-26T17:23:38.696185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:38.919746Z","iopub.execute_input":"2022-02-26T17:23:38.920011Z","iopub.status.idle":"2022-02-26T17:23:38.927444Z","shell.execute_reply.started":"2022-02-26T17:23:38.919982Z","shell.execute_reply":"2022-02-26T17:23:38.926782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#查看Age分布，看看有无左右偏的情况\nax = train_data['Age'].hist(bins=15,density=True,stacked=True,color='teal',alpha=0.6)\ntrain_data['Age'].plot(kind='density',color='teal')\nax.set(xlabel='Age')\nplt.xlim(-10,85)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:39.141582Z","iopub.execute_input":"2022-02-26T17:23:39.142318Z","iopub.status.idle":"2022-02-26T17:23:39.368052Z","shell.execute_reply.started":"2022-02-26T17:23:39.142279Z","shell.execute_reply":"2022-02-26T17:23:39.367524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 有点右偏，所以选择中位数填充好一些\ntrain_data['Age'] = train_data['Age'].fillna(train_data['Age'].median(skipna=True))","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:39.369059Z","iopub.execute_input":"2022-02-26T17:23:39.369693Z","iopub.status.idle":"2022-02-26T17:23:39.376273Z","shell.execute_reply.started":"2022-02-26T17:23:39.369645Z","shell.execute_reply":"2022-02-26T17:23:39.375422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 删除\ntrain_data = train_data.drop('Name',axis=1)\ntrain_data = train_data.drop('Ticket',axis=1)\ntrain_data = train_data.drop('PassengerId',axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:39.530842Z","iopub.execute_input":"2022-02-26T17:23:39.531131Z","iopub.status.idle":"2022-02-26T17:23:39.538259Z","shell.execute_reply.started":"2022-02-26T17:23:39.5311Z","shell.execute_reply":"2022-02-26T17:23:39.53759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 查看缺失值及其比例\nper_na = pd.concat([pd.Series(train_data.isna().sum().values),pd.Series((train_data.isna().sum().values / train_data.shape[0])*100)],axis=1)\nper_na.columns = ['Na_Counts','percentOfNa']\nper_na.index = train_data.columns\nper_na\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:39.776446Z","iopub.execute_input":"2022-02-26T17:23:39.776729Z","iopub.status.idle":"2022-02-26T17:23:39.793245Z","shell.execute_reply.started":"2022-02-26T17:23:39.776694Z","shell.execute_reply":"2022-02-26T17:23:39.792436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 处理测试集","metadata":{}},{"cell_type":"code","source":"test_df = test_df.drop('Name',axis=1)\ntest_df = test_df.drop('Ticket',axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:40.67526Z","iopub.execute_input":"2022-02-26T17:23:40.675539Z","iopub.status.idle":"2022-02-26T17:23:40.681783Z","shell.execute_reply.started":"2022-02-26T17:23:40.675506Z","shell.execute_reply":"2022-02-26T17:23:40.680896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 对测试集来进行处理\n# 查看缺失值及其比例\nper_na = pd.concat([pd.Series(test_df.isna().sum().values),pd.Series((test_df.isna().sum().values / test_df.shape[0])*100)],axis=1)\nper_na.columns = ['Na_Counts','percentOfNa']\nper_na.index = test_df.columns\nper_na","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:40.883016Z","iopub.execute_input":"2022-02-26T17:23:40.883731Z","iopub.status.idle":"2022-02-26T17:23:40.898862Z","shell.execute_reply.started":"2022-02-26T17:23:40.883687Z","shell.execute_reply":"2022-02-26T17:23:40.89825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 同样处理\ntest_df['Age'] = test_df['Age'].fillna(test_df['Age'].median(skipna=True))\ntest_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].median(skipna=True))\ntest_df = test_df.drop('Cabin',axis=1)\nper_na = pd.concat([pd.Series(test_df.isna().sum().values),pd.Series((test_df.isna().sum().values / test_df.shape[0])*100)],axis=1)\nper_na.columns = ['Na_Counts','percentOfNa']\nper_na.index = test_df.columns\nper_na","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:41.084424Z","iopub.execute_input":"2022-02-26T17:23:41.084904Z","iopub.status.idle":"2022-02-26T17:23:41.102228Z","shell.execute_reply.started":"2022-02-26T17:23:41.084865Z","shell.execute_reply":"2022-02-26T17:23:41.10139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 查看特征","metadata":{}},{"cell_type":"code","source":"# 查看特征\n#填充效果可视化\nplt.figure(figsize=(15,8))\nax = train_df['Age'].hist(bins=15,density=True,stacked=True,color='teal',alpha=0.6)\ntrain_df['Age'].plot(kind='density',color='teal')\nax = train_data['Age'].hist(bins=15,density=True,stacked=True,color='orange',alpha=0.5)\ntrain_data['Age'].plot(kind='density',color='orange')\nax.set(xlabel='Age')\nplt.xlim(-10,85)\nplt.legend(['Ordinary Age','Adjusted Age'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:41.607301Z","iopub.execute_input":"2022-02-26T17:23:41.608153Z","iopub.status.idle":"2022-02-26T17:23:41.929091Z","shell.execute_reply.started":"2022-02-26T17:23:41.60811Z","shell.execute_reply":"2022-02-26T17:23:41.92827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 异常值处理\n#box plot overallqual/saleprice\nlist1 = []\nfor i in train_data.columns.tolist()[1:]:\n    if i not in train_data.columns[train_data.dtypes =='object'].tolist():\n        list1.append(i)\nplt.figure(figsize=(25,15))\nfor i in range(len(list1)):\n    ax = plt.subplot(231+i)\n    sns.boxplot(x='Survived',y=list1[i],data=train_data)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:41.930715Z","iopub.execute_input":"2022-02-26T17:23:41.930957Z","iopub.status.idle":"2022-02-26T17:23:42.639468Z","shell.execute_reply.started":"2022-02-26T17:23:41.930929Z","shell.execute_reply":"2022-02-26T17:23:42.63867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot('Pclass',y='Survived',data=train_data,color=\"darkturquoise\")\nplt.legend(['Dead','Survived'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:42.641016Z","iopub.execute_input":"2022-02-26T17:23:42.641263Z","iopub.status.idle":"2022-02-26T17:23:42.91294Z","shell.execute_reply.started":"2022-02-26T17:23:42.641232Z","shell.execute_reply":"2022-02-26T17:23:42.91213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot('Embarked', 'Survived', data=train_data, color=\"teal\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:42.914213Z","iopub.execute_input":"2022-02-26T17:23:42.914413Z","iopub.status.idle":"2022-02-26T17:23:43.160491Z","shell.execute_reply.started":"2022-02-26T17:23:42.914388Z","shell.execute_reply":"2022-02-26T17:23:43.159444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot('Sex', 'Survived', data=train_df, color=\"aquamarine\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:43.164358Z","iopub.execute_input":"2022-02-26T17:23:43.164673Z","iopub.status.idle":"2022-02-26T17:23:43.386397Z","shell.execute_reply.started":"2022-02-26T17:23:43.164629Z","shell.execute_reply":"2022-02-26T17:23:43.385639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.columns","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:43.38732Z","iopub.execute_input":"2022-02-26T17:23:43.387514Z","iopub.status.idle":"2022-02-26T17:23:43.393331Z","shell.execute_reply.started":"2022-02-26T17:23:43.387491Z","shell.execute_reply":"2022-02-26T17:23:43.3927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:43.394239Z","iopub.execute_input":"2022-02-26T17:23:43.394713Z","iopub.status.idle":"2022-02-26T17:23:43.408283Z","shell.execute_reply.started":"2022-02-26T17:23:43.39468Z","shell.execute_reply":"2022-02-26T17:23:43.407585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nf_names = ['Sex','Embarked']\ntrain_data_Enlabel = train_data.copy()\nfor x in f_names:\n    label = preprocessing.LabelEncoder()\n    train_data_Enlabel[x] = label.fit_transform(train_data_Enlabel[x])\nfeature_col = train_data_Enlabel.columns\nfeature_col = feature_col.tolist()\nsns.pairplot(train_data_Enlabel[feature_col],hue=\"Survived\")","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:43.409553Z","iopub.execute_input":"2022-02-26T17:23:43.409859Z","iopub.status.idle":"2022-02-26T17:23:54.34541Z","shell.execute_reply.started":"2022-02-26T17:23:43.409827Z","shell.execute_reply":"2022-02-26T17:23:54.344624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 独热编码化\nlabel_list = list(dict(train_data.dtypes[train_data.dtypes =='object']).keys())\ntrain_data = pd.concat([train_data,pd.get_dummies(train_data[label_list])],axis=1)\ntrain_data = train_data.drop(label_list,axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:54.346689Z","iopub.execute_input":"2022-02-26T17:23:54.346922Z","iopub.status.idle":"2022-02-26T17:23:54.361174Z","shell.execute_reply.started":"2022-02-26T17:23:54.34689Z","shell.execute_reply":"2022-02-26T17:23:54.360158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cmap = sns.diverging_palette(220, 10, as_cmap=True) # 设置配色\nax=sns.clustermap(train_data.corr(),cmap=cmap,figsize=(8,8),annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:54.363504Z","iopub.execute_input":"2022-02-26T17:23:54.364044Z","iopub.status.idle":"2022-02-26T17:23:55.487956Z","shell.execute_reply.started":"2022-02-26T17:23:54.364011Z","shell.execute_reply":"2022-02-26T17:23:55.487058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\npca = PCA(n_components = 1)\nx = train_data[['SibSp', 'Parch']]\nx = StandardScaler().fit_transform(x)\nprincipalComponents = pca.fit_transform(x)\ntrain_data['PCA_sibspAndParch'] = principalComponents","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:55.489163Z","iopub.execute_input":"2022-02-26T17:23:55.489396Z","iopub.status.idle":"2022-02-26T17:23:55.504515Z","shell.execute_reply.started":"2022-02-26T17:23:55.489366Z","shell.execute_reply":"2022-02-26T17:23:55.503283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn\nsklearn.__version__","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:55.506389Z","iopub.execute_input":"2022-02-26T17:23:55.507592Z","iopub.status.idle":"2022-02-26T17:23:55.518074Z","shell.execute_reply.started":"2022-02-26T17:23:55.507554Z","shell.execute_reply":"2022-02-26T17:23:55.51698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install -U scikit-learn\n#要升级kaggle里面的sklearn版本，不然会报错，\n# kaggle环境版本太低了，所以直接在下面写了输出结果\n\n\n# from sklearn.feature_selection import RFECV\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.feature_selection import RFE\n# # Create the RFE object and compute a cross-validated score.\n# # The \"accuracy\" scoring is proportional to the number of correct classifications\n# X = train_data[train_data.columns[1:]]\n# X = X.astype('float64')\n# y = train_data['Survived']\n# rfecv = RFECV(estimator=LogisticRegression(), step=1, cv=5, scoring='accuracy')\n# rfecv.fit(X, y)\n\n# print(\"Optimal number of features: %d\" % rfecv.n_features_)\n# print('Selected features: %s' % list(X.columns[rfecv.support_]))\n\n# # Plot number of features VS. cross-validation scores\n# plt.figure(figsize=(10,6))\n# plt.xlabel(\"Number of features selected\")\n# plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n# plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n# plt.show()\n\n\n#输出的结果是：\n# Optimal number of features: 9\n#Selected features: ['Pclass', 'Age', 'SibSp', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'PCA_sibspAndParch']","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:55.520411Z","iopub.execute_input":"2022-02-26T17:23:55.521151Z","iopub.status.idle":"2022-02-26T17:23:55.528415Z","shell.execute_reply.started":"2022-02-26T17:23:55.521086Z","shell.execute_reply":"2022-02-26T17:23:55.527863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Selected_features = ['Pclass', 'SibSp', 'Parch', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'PCA_sibspAndParch']\nX = train_data[Selected_features]\n\nplt.subplots(figsize=(8, 5))\nsns.heatmap(X.corr(), annot=True, cmap=\"RdYlGn\")\nplt.show()\n# sibSp 和Parch相关系数比较高，删掉1个或降维","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:55.530242Z","iopub.execute_input":"2022-02-26T17:23:55.53109Z","iopub.status.idle":"2022-02-26T17:23:56.167453Z","shell.execute_reply.started":"2022-02-26T17:23:55.531021Z","shell.execute_reply":"2022-02-26T17:23:56.166625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fe_list=['Pclass', 'Age', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S','PCA_sibspAndParch']","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:56.168832Z","iopub.execute_input":"2022-02-26T17:23:56.169033Z","iopub.status.idle":"2022-02-26T17:23:56.173038Z","shell.execute_reply.started":"2022-02-26T17:23:56.169009Z","shell.execute_reply":"2022-02-26T17:23:56.172202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score \nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\nX = train_data[fe_list]\nX = StandardScaler().fit_transform(X)\ny = train_data['Survived']\n\n#Define simple model\n###############################################################################\nC = np.arange(1e-05, 5.5, 0.1)\nscoring = {'Accuracy': 'accuracy', 'AUC': 'roc_auc', 'Log_loss': 'neg_log_loss'}\nlog_reg = LogisticRegression()\n\n#Simple pre-processing estimators\n###############################################################################\nstd_scale = StandardScaler(with_mean=False, with_std=False)\n#std_scale = StandardScaler()\n\n#Defining the CV method: Using the Repeated Stratified K Fold\n###############################################################################\n\nn_folds=5\nn_repeats=5\n\nrskfold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=n_repeats, random_state=2022)\n\n#Creating simple pipeline and defining the gridsearch\n###############################################################################\n\nlog_clf_pipe = Pipeline(steps=[('scale',std_scale), ('clf',log_reg)])\n\nlog_clf = GridSearchCV(estimator=log_clf_pipe, cv=rskfold,\n              scoring=scoring, return_train_score=True,\n              param_grid=dict(clf__C=C), refit='Accuracy')\n\nlog_clf.fit(X, y)\nresults = log_clf.cv_results_\n\nprint('='*20)\nprint(\"best params: \" + str(log_clf.best_estimator_))\nprint(\"best params: \" + str(log_clf.best_params_))\nprint('best score:', log_clf.best_score_)\nprint('='*20)\n\nplt.figure(figsize=(10, 10))\nplt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\",fontsize=16)\n\nplt.xlabel(\"Inverse of regularization strength: C\")\nplt.ylabel(\"Score\")\nplt.grid()\n\nax = plt.axes()\nax.set_xlim(0, C.max()) \nax.set_ylim(0.35, 0.95)\n\nX_axis = np.array(results['param_clf__C'].data, dtype=float)\n\nfor scorer, color in zip(list(scoring.keys()), ['g', 'k', 'b']): \n    for sample, style in (('train', '--'), ('test', '-')):\n        sample_score_mean = -results['mean_%s_%s' % (sample, scorer)] if scoring[scorer]=='neg_log_loss' else results['mean_%s_%s' % (sample, scorer)]\n        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n                        sample_score_mean + sample_score_std,\n                        alpha=0.1 if sample == 'test' else 0, color=color)\n        ax.plot(X_axis, sample_score_mean, style, color=color,\n                alpha=1 if sample == 'test' else 0.7,\n                label=\"%s (%s)\" % (scorer, sample))\n\n    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n    best_score = -results['mean_test_%s' % scorer][best_index] if scoring[scorer]=='neg_log_loss' else results['mean_test_%s' % scorer][best_index]\n        \n    # Plot a dotted vertical line at the best score for that scorer marked by x\n    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n\n    # Annotate the best score for that scorer\n    ax.annotate(\"%0.2f\" % best_score,\n                (X_axis[best_index], best_score + 0.005))\n\nplt.legend(loc=\"best\")\nplt.grid('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:56.174786Z","iopub.execute_input":"2022-02-26T17:23:56.175056Z","iopub.status.idle":"2022-02-26T17:23:59.002771Z","shell.execute_reply.started":"2022-02-26T17:23:56.17496Z","shell.execute_reply":"2022-02-26T17:23:59.001346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\npca = PCA(n_components = 1)\nx = test_df[['SibSp', 'Parch']]\nx = StandardScaler().fit_transform(x)\nprincipalComponents = pca.fit_transform(x)\ntest_df['PCA_sibspAndParch'] = principalComponents\ntest_df = pd.concat([test_df,pd.get_dummies(test_df[['Sex','Embarked']])],axis=1)\nfinal_test=pd.DataFrame()\nfinal_test['PassengerId'] = test_df['PassengerId']\nfinal_test['Survived'] = log_clf.predict(StandardScaler().fit_transform(test_df[fe_list]))\n\n\nsubmission = final_test[['PassengerId','Survived']]\n\nsubmission.to_csv(\"submission.csv\", index=False)\n\nsubmission.tail()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:59.004296Z","iopub.status.idle":"2022-02-26T17:23:59.004892Z","shell.execute_reply.started":"2022-02-26T17:23:59.004679Z","shell.execute_reply":"2022-02-26T17:23:59.004707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(train_data[train_data.columns[1:]], train_data[train_data.columns[0]], test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T20:48:24.783608Z","iopub.execute_input":"2022-02-17T20:48:24.783997Z","iopub.status.idle":"2022-02-17T20:48:24.796142Z","shell.execute_reply.started":"2022-02-17T20:48:24.783953Z","shell.execute_reply":"2022-02-17T20:48:24.794803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 随机森林调参","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(random_state=2022)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T20:48:24.7982Z","iopub.execute_input":"2022-02-17T20:48:24.798881Z","iopub.status.idle":"2022-02-17T20:48:24.98615Z","shell.execute_reply.started":"2022-02-17T20:48:24.798816Z","shell.execute_reply":"2022-02-17T20:48:24.983701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = { \n    'n_estimators': list(range(1,11)),\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'max_depth' : [4,5,6,7,8],\n    'criterion' :['gini', 'entropy']\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-17T20:48:24.989375Z","iopub.execute_input":"2022-02-17T20:48:24.990361Z","iopub.status.idle":"2022-02-17T20:48:25.000183Z","shell.execute_reply.started":"2022-02-17T20:48:24.990287Z","shell.execute_reply":"2022-02-17T20:48:24.997863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\nCV_rfc.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T20:48:25.005806Z","iopub.execute_input":"2022-02-17T20:48:25.00619Z","iopub.status.idle":"2022-02-17T20:49:05.507625Z","shell.execute_reply.started":"2022-02-17T20:48:25.006152Z","shell.execute_reply":"2022-02-17T20:49:05.50672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CV_rfc.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-02-17T20:49:05.509081Z","iopub.execute_input":"2022-02-17T20:49:05.509356Z","iopub.status.idle":"2022-02-17T20:49:05.51602Z","shell.execute_reply.started":"2022-02-17T20:49:05.509325Z","shell.execute_reply":"2022-02-17T20:49:05.514708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc1=RandomForestClassifier(random_state=2022, criterion='gini',max_depth=4,max_features='auto',n_estimators= 7)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T20:49:05.517935Z","iopub.execute_input":"2022-02-17T20:49:05.518556Z","iopub.status.idle":"2022-02-17T20:49:05.533976Z","shell.execute_reply.started":"2022-02-17T20:49:05.518503Z","shell.execute_reply":"2022-02-17T20:49:05.532505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc1.fit(x_train, y_train)\npred=rfc1.predict(x_test)\nprint(\"Accuracy for Random Forest on CV data: \",accuracy_score(y_test,pred))","metadata":{"execution":{"iopub.status.busy":"2022-02-17T20:49:05.535683Z","iopub.execute_input":"2022-02-17T20:49:05.536095Z","iopub.status.idle":"2022-02-17T20:49:05.579293Z","shell.execute_reply.started":"2022-02-17T20:49:05.536056Z","shell.execute_reply":"2022-02-17T20:49:05.578438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"op_rf=rfc1.predict(test_df.drop(['Sex','Embarked'],axis=1).iloc[:,1:][x_train.columns])","metadata":{"execution":{"iopub.status.busy":"2022-02-17T20:49:05.582338Z","iopub.execute_input":"2022-02-17T20:49:05.582897Z","iopub.status.idle":"2022-02-17T20:49:05.595249Z","shell.execute_reply.started":"2022-02-17T20:49:05.582845Z","shell.execute_reply":"2022-02-17T20:49:05.594165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"op=pd.DataFrame(test_df['PassengerId'])\nop['Survived']=op_rf\nop.to_csv(\"op_rf.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T20:49:05.596418Z","iopub.execute_input":"2022-02-17T20:49:05.598057Z","iopub.status.idle":"2022-02-17T20:49:05.613215Z","shell.execute_reply.started":"2022-02-17T20:49:05.597978Z","shell.execute_reply":"2022-02-17T20:49:05.611557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 模型融合","metadata":{}},{"cell_type":"code","source":"op_rf=rfc1.predict_proba(test_df.drop(['Sex','Embarked'],axis=1).iloc[:,1:][x_train.columns])\nlog_clf1 = log_clf.predict_proba(StandardScaler().fit_transform(test_df[fe_list]))","metadata":{"execution":{"iopub.status.busy":"2022-02-17T20:49:05.614844Z","iopub.execute_input":"2022-02-17T20:49:05.615366Z","iopub.status.idle":"2022-02-17T20:49:05.642936Z","shell.execute_reply.started":"2022-02-17T20:49:05.615319Z","shell.execute_reply":"2022-02-17T20:49:05.641102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_result = pd.DataFrame(op_rf+log_clf1) #直接把两个模型预测的概率相加","metadata":{"execution":{"iopub.status.busy":"2022-02-17T20:49:05.644983Z","iopub.execute_input":"2022-02-17T20:49:05.645381Z","iopub.status.idle":"2022-02-17T20:49:05.655042Z","shell.execute_reply.started":"2022-02-17T20:49:05.645336Z","shell.execute_reply":"2022-02-17T20:49:05.653398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_result","metadata":{"execution":{"iopub.status.busy":"2022-02-17T20:49:05.657061Z","iopub.execute_input":"2022-02-17T20:49:05.657432Z","iopub.status.idle":"2022-02-17T20:49:05.681492Z","shell.execute_reply.started":"2022-02-17T20:49:05.657386Z","shell.execute_reply":"2022-02-17T20:49:05.680474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ave_result=pd.DataFrame()\nave_result['PassengerId'] =test_df['PassengerId']\nave_result['Survived'] = df_result.idxmax(1) # 取出概率的分类类别","metadata":{"execution":{"iopub.status.busy":"2022-02-17T20:49:05.68307Z","iopub.execute_input":"2022-02-17T20:49:05.683352Z","iopub.status.idle":"2022-02-17T20:49:05.701881Z","shell.execute_reply.started":"2022-02-17T20:49:05.683321Z","shell.execute_reply":"2022-02-17T20:49:05.700835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ave_result.to_csv('./ave_result.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T20:49:05.703722Z","iopub.execute_input":"2022-02-17T20:49:05.704043Z","iopub.status.idle":"2022-02-17T20:49:05.727691Z","shell.execute_reply.started":"2022-02-17T20:49:05.704002Z","shell.execute_reply":"2022-02-17T20:49:05.726882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGB","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n# 载入必要的库\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\n\nimport missingno as msno\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\npca = PCA(n_components = 1)\nx = test_df[['SibSp', 'Parch']]\nx = StandardScaler().fit_transform(x)\nprincipalComponents = pca.fit_transform(x)\ntest_df['PCA_sibspAndParch'] = principalComponents\ntest_df = pd.concat([test_df,pd.get_dummies(test_df[['Sex','Embarked']])],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:10.156561Z","iopub.execute_input":"2022-02-26T17:24:10.156869Z","iopub.status.idle":"2022-02-26T17:24:10.177424Z","shell.execute_reply.started":"2022-02-26T17:24:10.156834Z","shell.execute_reply":"2022-02-26T17:24:10.176632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test_df\nfeatures = fe_list\ntrain = train_data\ntrain[features]","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:11.30502Z","iopub.execute_input":"2022-02-26T17:24:11.305864Z","iopub.status.idle":"2022-02-26T17:24:11.323695Z","shell.execute_reply.started":"2022-02-26T17:24:11.305811Z","shell.execute_reply":"2022-02-26T17:24:11.322737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(DTR.get_params())\nparams = {\"objective\": \"reg:logistic\", # for linear regression\n          \"eta\": 0.004,   # learning rate\n          \"max_depth\": 12,    # maximum depth of a tree\n          \"subsample\": 0.7,    # Subsample ratio of the training instances\n          \"colsample_bytree\": 0.5,   # Subsample ratio of columns when constructing each tree\n          \"silent\": 1,   # silent mode\n          \"seed\": 10   # Random number seed\n          }\nnum_trees = 9500","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:11.726563Z","iopub.execute_input":"2022-02-26T17:24:11.72687Z","iopub.status.idle":"2022-02-26T17:24:11.732033Z","shell.execute_reply.started":"2022-02-26T17:24:11.726837Z","shell.execute_reply":"2022-02-26T17:24:11.731093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test = train_test_split(train, test_size=0.2, random_state=2022)\n\ndtrain = xgb.DMatrix(X_train[features], np.log1p(X_train.Survived))\ndvalid = xgb.DMatrix(X_test[features], np.log1p(X_test.Survived))\ndtest = xgb.DMatrix(test[features])\n\nwatchlist = [(dtrain, 'train'),(dvalid, 'eval')]\ngbm = xgb.train(params, dtrain, num_trees, evals=watchlist, early_stopping_rounds=50, verbose_eval=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:33:11.181772Z","iopub.execute_input":"2022-02-26T17:33:11.182612Z","iopub.status.idle":"2022-02-26T17:33:17.039866Z","shell.execute_reply.started":"2022-02-26T17:33:11.182563Z","shell.execute_reply":"2022-02-26T17:33:17.039149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_probs = gbm.predict(xgb.DMatrix(test[features]), ntree_limit=gbm.best_ntree_limit)\nindices = test_probs < 0\nindices2 = test_probs > 0.5\nindices3 = test_probs <= 0.5\ntest_probs[indices] = 0\ntest_probs[indices2] = 1\ntest_probs[indices3] = 0\ntest_probs =test_probs.astype('int')\nsubmission = pd.DataFrame({\"PassengerId\": final_test[\"PassengerId\"], \"Survived\": test_probs})\nsubmission.to_csv(\"./XGB.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:41:21.7284Z","iopub.execute_input":"2022-02-26T17:41:21.728712Z","iopub.status.idle":"2022-02-26T17:41:21.756848Z","shell.execute_reply.started":"2022-02-26T17:41:21.728677Z","shell.execute_reply":"2022-02-26T17:41:21.756128Z"},"trusted":true},"execution_count":null,"outputs":[]}]}